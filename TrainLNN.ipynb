{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8afa7df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score\n",
    "from scipy import signal\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "# Configuration\n",
    "class Config:\n",
    "    # Data parameters\n",
    "    sampling_rate = 256\n",
    "    window_size = 10 * sampling_rate  # 10 seconds\n",
    "    stride = 1 * sampling_rate  # 1 second\n",
    "    num_channels = 18  # CHB-MIT typical\n",
    "    \n",
    "    # Model architecture\n",
    "    encoder_dim = 64\n",
    "    ltc_neurons1 = 64\n",
    "    ltc_neurons2 = 48\n",
    "    attention_heads = 2\n",
    "    attention_dim = 32\n",
    "    \n",
    "    # Training\n",
    "    batch_size = 32\n",
    "    learning_rate = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    epochs = 100\n",
    "    dropout_rate = 0.1\n",
    "    \n",
    "    # LTC parameters\n",
    "    min_time_constant = 0.01  # 10ms\n",
    "    max_time_constant = 10.0  # 10 seconds\n",
    "    \n",
    "    # Loss weights\n",
    "    lambda_pred = 0.7\n",
    "    mu_reg = 1e-5\n",
    "    gamma_lead = 2.0\n",
    "    \n",
    "    # Pre-ictal window (5 minutes for prediction)\n",
    "    preictal_window = 300  # seconds\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e686ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral frontend: input torch.Size([2, 18, 2560]) -> output torch.Size([2, 288, 81])\n"
     ]
    }
   ],
   "source": [
    "class SpectralFrontend(nn.Module):\n",
    "    \"\"\"Learnable filterbank spectral front-end\"\"\"\n",
    "    def __init__(self, num_channels, out_channels=16):\n",
    "        super(SpectralFrontend, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        # Depthwise convolutions for each channel\n",
    "        self.filterbanks = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(1, out_channels, kernel_size=128, stride=32, padding=64, bias=False),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                nn.GELU()\n",
    "            ) for _ in range(num_channels)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, channels, time)\n",
    "        batch_size, num_channels, time_steps = x.shape\n",
    "        \n",
    "        # Apply filterbank to each channel\n",
    "        processed_channels = []\n",
    "        for i in range(num_channels):\n",
    "            channel_data = x[:, i:i+1, :]  # (batch, 1, time)\n",
    "            processed = self.filterbanks[i](channel_data)  # (batch, out_channels, time')\n",
    "            processed_channels.append(processed)\n",
    "        \n",
    "        # Concatenate all channels\n",
    "        output = torch.cat(processed_channels, dim=1)  # (batch, channels*out_channels, time')\n",
    "        return output\n",
    "\n",
    "# Test spectral frontend\n",
    "def test_spectral_frontend():\n",
    "    frontend = SpectralFrontend(config.num_channels).to(device)\n",
    "    x = torch.randn(2, config.num_channels, config.window_size).to(device)\n",
    "    output = frontend(x)\n",
    "    print(f\"Spectral frontend: input {x.shape} -> output {output.shape}\")\n",
    "    return frontend\n",
    "\n",
    "frontend = test_spectral_frontend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc4f9b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LTC layer: input torch.Size([2, 80, 64]) -> output torch.Size([2, 80, 64])\n",
      "Time constants shape: torch.Size([2, 80, 64])\n",
      "Mean time constant: 5.062s\n"
     ]
    }
   ],
   "source": [
    "class LTCLayer(nn.Module):\n",
    "    \"\"\"Liquid Time-Constant Continuous-time Layer\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, sparsity=0.2):\n",
    "        super(LTCLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Time constants (learnable per neuron)\n",
    "        self.log_tau = nn.Parameter(torch.randn(hidden_dim) * 0.1)\n",
    "        \n",
    "        # Input weights\n",
    "        self.W_x = nn.Linear(input_dim, hidden_dim, bias=False)\n",
    "        \n",
    "        # Sparse recurrent weights\n",
    "        self.W_h = self._create_sparse_weights(hidden_dim, hidden_dim, sparsity)\n",
    "        \n",
    "        # Bias\n",
    "        self.bias = nn.Parameter(torch.zeros(hidden_dim))\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "    def _create_sparse_weights(self, in_dim, out_dim, sparsity):\n",
    "        weight = torch.zeros(out_dim, in_dim)\n",
    "        num_nonzero = int(in_dim * out_dim * (1 - sparsity))\n",
    "        indices = torch.randperm(in_dim * out_dim)[:num_nonzero]\n",
    "        weight.view(-1)[indices] = torch.randn(num_nonzero) * 0.1\n",
    "        return nn.Parameter(weight)\n",
    "    \n",
    "    def get_time_constants(self):\n",
    "        \"\"\"Get time constants in actual seconds\"\"\"\n",
    "        tau = torch.sigmoid(self.log_tau) * (config.max_time_constant - config.min_time_constant) + config.min_time_constant\n",
    "        return tau\n",
    "    \n",
    "    def forward(self, x, initial_state=None):\n",
    "        # x shape: (batch, time, features)\n",
    "        batch_size, seq_len, input_dim = x.shape\n",
    "        \n",
    "        # Initialize hidden state\n",
    "        if initial_state is None:\n",
    "            h = torch.zeros(batch_size, self.hidden_dim, device=x.device)\n",
    "        else:\n",
    "            h = initial_state\n",
    "        \n",
    "        # Get time constants and compute alpha\n",
    "        tau = self.get_time_constants()  # (hidden_dim,)\n",
    "        dt = 1.0 / (config.sampling_rate / 32)  # Account for downsampling in frontend\n",
    "        alpha = torch.exp(-dt / tau)  # (hidden_dim,)\n",
    "        \n",
    "        hidden_states = []\n",
    "        time_constants = []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            # LTC dynamics\n",
    "            input_proj = self.W_x(x[:, t, :])  # (batch, hidden_dim)\n",
    "            recurrent = h @ self.W_h.t()  # (batch, hidden_dim)\n",
    "            \n",
    "            # Update equation\n",
    "            h = alpha * h + (1 - alpha) * torch.tanh(input_proj + recurrent + self.bias)\n",
    "            h = self.layer_norm(h)\n",
    "            \n",
    "            hidden_states.append(h.unsqueeze(1))\n",
    "            time_constants.append(tau.unsqueeze(0).expand(batch_size, -1).unsqueeze(1))\n",
    "        \n",
    "        hidden_sequence = torch.cat(hidden_states, dim=1)  # (batch, seq_len, hidden_dim)\n",
    "        time_constant_sequence = torch.cat(time_constants, dim=1)  # (batch, seq_len, hidden_dim)\n",
    "        \n",
    "        return hidden_sequence, time_constant_sequence\n",
    "\n",
    "# Test LTC layer\n",
    "def test_ltc_layer():\n",
    "    ltc = LTCLayer(64, config.ltc_neurons1).to(device)\n",
    "    x = torch.randn(2, 80, 64).to(device)  # (batch, time, features)\n",
    "    hidden_seq, tau_seq = ltc(x)\n",
    "    print(f\"LTC layer: input {x.shape} -> output {hidden_seq.shape}\")\n",
    "    print(f\"Time constants shape: {tau_seq.shape}\")\n",
    "    print(f\"Mean time constant: {ltc.get_time_constants().mean().item():.3f}s\")\n",
    "    return ltc\n",
    "\n",
    "ltc_layer = test_ltc_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "820702c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention gate: input torch.Size([2, 80, 48]) -> output torch.Size([2, 80, 48])\n",
      "Attention weights: torch.Size([2, 80, 80])\n",
      "Channel weights: torch.Size([2, 1, 48])\n"
     ]
    }
   ],
   "source": [
    "class TemporalAttentionGate(nn.Module):\n",
    "    \"\"\"Lightweight temporal and channel attention\"\"\"\n",
    "    def __init__(self, input_dim, num_heads=2, attention_dim=32):\n",
    "        super(TemporalAttentionGate, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_dim = attention_dim\n",
    "        \n",
    "        # Multi-head attention for temporal patterns\n",
    "        self.temporal_attention = nn.MultiheadAttention(\n",
    "            embed_dim=input_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=config.dropout_rate,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Channel-frequency gating\n",
    "        self.channel_gate = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(input_dim // 2, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.layer_norm1 = nn.LayerNorm(input_dim)\n",
    "        self.layer_norm2 = nn.LayerNorm(input_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, time, features)\n",
    "        \n",
    "        # Temporal attention\n",
    "        attended, attention_weights = self.temporal_attention(x, x, x)\n",
    "        x = self.layer_norm1(x + attended)\n",
    "        \n",
    "        # Channel gating\n",
    "        channel_weights = self.channel_gate(x.mean(dim=1))  # (batch, features)\n",
    "        channel_weights = channel_weights.unsqueeze(1)  # (batch, 1, features)\n",
    "        x = x * channel_weights\n",
    "        \n",
    "        x = self.layer_norm2(x)\n",
    "        return x, attention_weights, channel_weights\n",
    "\n",
    "# Test attention gate\n",
    "def test_attention_gate():\n",
    "    attention = TemporalAttentionGate(config.ltc_neurons2).to(device)\n",
    "    x = torch.randn(2, 80, config.ltc_neurons2).to(device)\n",
    "    output, attn_weights, channel_weights = attention(x)\n",
    "    print(f\"Attention gate: input {x.shape} -> output {output.shape}\")\n",
    "    print(f\"Attention weights: {attn_weights.shape}\")\n",
    "    print(f\"Channel weights: {channel_weights.shape}\")\n",
    "    return attention\n",
    "\n",
    "attention_gate = test_attention_gate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d78a0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 212,602\n",
      "Model outputs:\n",
      "  Detection: torch.Size([2, 1])\n",
      "  Prediction: torch.Size([2, 1])\n",
      "  Time constants 1: torch.Size([2, 81, 64])\n",
      "  Time constants 2: torch.Size([2, 81, 48])\n"
     ]
    }
   ],
   "source": [
    "class LightLTCSeizNet(nn.Module):\n",
    "    \"\"\"Complete LTC-based seizure prediction model\"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(LightLTCSeizNet, self).__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # Spectral front-end\n",
    "        self.spectral_frontend = SpectralFrontend(config.num_channels)\n",
    "        frontend_output_dim = config.num_channels * 16\n",
    "        \n",
    "        # Channel encoder - FIXED: removed groups parameter\n",
    "        self.channel_encoder = nn.Sequential(\n",
    "            nn.Conv1d(frontend_output_dim, config.encoder_dim, kernel_size=7, \n",
    "                     stride=1, padding=3),  # Removed groups parameter\n",
    "            nn.BatchNorm1d(config.encoder_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(config.encoder_dim, config.encoder_dim, kernel_size=1),\n",
    "            nn.BatchNorm1d(config.encoder_dim),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        \n",
    "        # LTC blocks\n",
    "        self.ltc1 = LTCLayer(config.encoder_dim, config.ltc_neurons1)\n",
    "        self.ltc2 = LTCLayer(config.ltc_neurons1, config.ltc_neurons2)\n",
    "        \n",
    "        # Residual connection\n",
    "        self.residual_proj = nn.Linear(config.encoder_dim, config.ltc_neurons2)\n",
    "        \n",
    "        # Attention gate\n",
    "        self.attention_gate = TemporalAttentionGate(config.ltc_neurons2)\n",
    "        \n",
    "        # Readout heads\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.global_max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        # Detection head (instant seizure)\n",
    "        self.detect_head = nn.Sequential(\n",
    "            nn.Linear(config.ltc_neurons2 * 2, 64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(config.dropout_rate),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Prediction head (pre-ictal)\n",
    "        self.pred_head = nn.Sequential(\n",
    "            nn.Linear(config.ltc_neurons2 * 2, 64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(config.dropout_rate),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "        \n",
    "        print(f\"Total parameters: {sum(p.numel() for p in self.parameters()):,}\")\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights properly\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, channels, time)\n",
    "        batch_size, channels, time_steps = x.shape\n",
    "        \n",
    "        # Spectral front-end\n",
    "        x_spectral = self.spectral_frontend(x)  # (batch, channels*16, time')\n",
    "        \n",
    "        # Channel encoder\n",
    "        x_encoded = self.channel_encoder(x_spectral)  # (batch, encoder_dim, time')\n",
    "        x_encoded = x_encoded.transpose(1, 2)  # (batch, time', encoder_dim)\n",
    "        \n",
    "        # LTC blocks\n",
    "        h1, tau1 = self.ltc1(x_encoded)\n",
    "        h2, tau2 = self.ltc2(h1)\n",
    "        \n",
    "        # Residual connection\n",
    "        residual = self.residual_proj(x_encoded)\n",
    "        # Ensure residual matches the temporal dimension of h2\n",
    "        residual = residual[:, :h2.size(1), :]\n",
    "        h2 = h2 + residual\n",
    "        \n",
    "        # Attention gate\n",
    "        h_attended, attention_weights, channel_weights = self.attention_gate(h2)\n",
    "        \n",
    "        # Pooling\n",
    "        avg_pool = self.global_pool(h_attended.transpose(1, 2)).squeeze(-1)\n",
    "        max_pool = self.global_max_pool(h_attended.transpose(1, 2)).squeeze(-1)\n",
    "        pooled = torch.cat([avg_pool, max_pool], dim=1)\n",
    "        \n",
    "        # Readout\n",
    "        p_detect = self.detect_head(pooled)\n",
    "        p_pred = self.pred_head(pooled)\n",
    "        \n",
    "        return {\n",
    "            'detection': p_detect,\n",
    "            'prediction': p_pred,\n",
    "            'attention_weights': attention_weights,\n",
    "            'channel_weights': channel_weights,\n",
    "            'time_constants1': tau1,\n",
    "            'time_constants2': tau2\n",
    "        }\n",
    "\n",
    "# Test complete model\n",
    "def test_complete_model():\n",
    "    model = LightLTCSeizNet(config).to(device)\n",
    "    x = torch.randn(2, config.num_channels, config.window_size).to(device)\n",
    "    outputs = model(x)\n",
    "    \n",
    "    print(f\"Model outputs:\")\n",
    "    print(f\"  Detection: {outputs['detection'].shape}\")\n",
    "    print(f\"  Prediction: {outputs['prediction'].shape}\")\n",
    "    print(f\"  Time constants 1: {outputs['time_constants1'].shape}\")\n",
    "    print(f\"  Time constants 2: {outputs['time_constants2'].shape}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = test_complete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "547970b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mne'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmne\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mglob\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'mne'"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CHBMITDataset(Dataset):\n",
    "    \"\"\"Real CHB-MIT Scalp EEG Dataset Loader\"\"\"\n",
    "    def __init__(self, data_path, window_size=2560, stride=256, mode='train', \n",
    "                 subjects=None, preictal_window=300, sampling_rate=256):\n",
    "        self.data_path = data_path\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.mode = mode\n",
    "        self.preictal_window = preictal_window\n",
    "        self.sampling_rate = sampling_rate\n",
    "        \n",
    "        # Discover available subjects and files\n",
    "        self.subjects = self._discover_subjects()\n",
    "        if subjects:\n",
    "            self.subjects = [s for s in self.subjects if s in subjects]\n",
    "        \n",
    "        # Load all data and annotations\n",
    "        self.samples = self._load_all_data()\n",
    "        \n",
    "        print(f\"Loaded {len(self.samples)} samples for {mode} mode across {len(self.subjects)} subjects\")\n",
    "        \n",
    "    def _discover_subjects(self):\n",
    "        \"\"\"Discover available subjects in CHB-MIT dataset\"\"\"\n",
    "        subjects = []\n",
    "        chb_dir = os.path.join(self.data_path, 'chb-mit-scalp-eeg-database-1.0.0')\n",
    "        if not os.path.exists(chb_dir):\n",
    "            # If the structure is different, try to find subject directories\n",
    "            chb_dir = self.data_path\n",
    "            \n",
    "        for item in os.listdir(chb_dir):\n",
    "            if item.startswith('chb') and os.path.isdir(os.path.join(chb_dir, item)):\n",
    "                subjects.append(item)\n",
    "        return sorted(subjects)\n",
    "    \n",
    "    def _load_all_data(self):\n",
    "        \"\"\"Load all EEG data and create labeled windows\"\"\"\n",
    "        all_samples = []\n",
    "        \n",
    "        for subject in self.subjects:\n",
    "            subject_dir = os.path.join(self.data_path, 'chb-mit-scalp-eeg-database-1.0.0', subject)\n",
    "            if not os.path.exists(subject_dir):\n",
    "                print(f\"Subject directory not found: {subject_dir}\")\n",
    "                continue\n",
    "                \n",
    "            # Find all EDF files for this subject\n",
    "            edf_files = glob.glob(os.path.join(subject_dir, \"*.edf\"))\n",
    "            summary_file = os.path.join(subject_dir, f\"{subject}-summary.txt\")\n",
    "            \n",
    "            # Load seizure annotations from summary file\n",
    "            seizure_times = self._load_seizure_annotations(summary_file, subject)\n",
    "            \n",
    "            for edf_file in edf_files:\n",
    "                try:\n",
    "                    # Load EDF file\n",
    "                    raw = mne.io.read_raw_edf(edf_file, preload=False, verbose=False)\n",
    "                    \n",
    "                    # Resample to target sampling rate if needed\n",
    "                    if raw.info['sfreq'] != self.sampling_rate:\n",
    "                        raw = raw.resample(self.sampling_rate)\n",
    "                    \n",
    "                    # Get data (only EEG channels)\n",
    "                    eeg_channels = [ch for ch in raw.ch_names if 'EEG' in ch]\n",
    "                    if len(eeg_channels) < config.num_channels:\n",
    "                        print(f\"Warning: Only {len(eeg_channels)} EEG channels found in {edf_file}\")\n",
    "                        continue\n",
    "                        \n",
    "                    # Select first config.num_channels for consistency\n",
    "                    eeg_channels = eeg_channels[:config.num_channels]\n",
    "                    raw.pick_channels(eeg_channels)\n",
    "                    \n",
    "                    # Get the actual data\n",
    "                    data, times = raw[:, :]\n",
    "                    data = data.astype(np.float32)\n",
    "                    \n",
    "                    # Normalize each channel\n",
    "                    data = (data - np.mean(data, axis=1, keepdims=True)) / (np.std(data, axis=1, keepdims=True) + 1e-8)\n",
    "                    \n",
    "                    # Create labeled windows for this file\n",
    "                    file_samples = self._create_windows_for_file(data, times, seizure_times, subject, edf_file)\n",
    "                    all_samples.extend(file_samples)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {edf_file}: {e}\")\n",
    "                    continue\n",
    "                    \n",
    "        return all_samples\n",
    "    \n",
    "    def _load_seizure_annotations(self, summary_file, subject):\n",
    "        \"\"\"Load seizure annotations from summary file\"\"\"\n",
    "        seizure_times = []\n",
    "        \n",
    "        if not os.path.exists(summary_file):\n",
    "            print(f\"Summary file not found: {summary_file}\")\n",
    "            return seizure_times\n",
    "            \n",
    "        try:\n",
    "            with open(summary_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            current_file = None\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if line.startswith('File Name:'):\n",
    "                    current_file = line.split(': ')[1]\n",
    "                elif line.startswith('Seizure Start Time:'):\n",
    "                    start_time = int(line.split(': ')[1].split()[0])\n",
    "                elif line.startswith('Seizure End Time:'):\n",
    "                    end_time = int(line.split(': ')[1].split()[0])\n",
    "                    if current_file:\n",
    "                        seizure_times.append({\n",
    "                            'file': current_file,\n",
    "                            'start': start_time,\n",
    "                            'end': end_time\n",
    "                        })\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading summary file {summary_file}: {e}\")\n",
    "            \n",
    "        return seizure_times\n",
    "    \n",
    "    def _create_windows_for_file(self, data, times, seizure_times, subject, edf_file):\n",
    "        \"\"\"Create labeled windows for a single EEG file\"\"\"\n",
    "        samples = []\n",
    "        num_samples = data.shape[1]\n",
    "        file_name = os.path.basename(edf_file)\n",
    "        \n",
    "        # Find seizures in this file\n",
    "        file_seizures = [sz for sz in seizure_times if sz['file'] == file_name]\n",
    "        \n",
    "        for start_idx in range(0, num_samples - self.window_size + 1, self.stride):\n",
    "            end_idx = start_idx + self.window_size\n",
    "            window_data = data[:, start_idx:end_idx]\n",
    "            \n",
    "            # Convert to time in seconds\n",
    "            window_center_sec = times[start_idx + self.window_size // 2]\n",
    "            \n",
    "            # Create labels\n",
    "            detection_label, prediction_label, timestamp = self._create_labels(\n",
    "                window_center_sec, file_seizures\n",
    "            )\n",
    "            \n",
    "            samples.append({\n",
    "                'eeg_data': window_data,\n",
    "                'detection_label': detection_label,\n",
    "                'prediction_label': prediction_label,\n",
    "                'timestamp': timestamp,\n",
    "                'subject': subject,\n",
    "                'file': file_name\n",
    "            })\n",
    "            \n",
    "        return samples\n",
    "    \n",
    "    def _create_labels(self, window_center_sec, file_seizures):\n",
    "        \"\"\"Create detection and prediction labels for a window\"\"\"\n",
    "        detection_label = 0\n",
    "        prediction_label = 0\n",
    "        timestamp = 0  # Time to nearest seizure\n",
    "        \n",
    "        if not file_seizures:\n",
    "            # No seizures in this file, all interictal\n",
    "            return 0, 0, 1000  # Large positive timestamp for interictal\n",
    "            \n",
    "        for seizure in file_seizures:\n",
    "            seizure_start = seizure['start']\n",
    "            seizure_end = seizure['end']\n",
    "            preictal_start = seizure_start - self.preictal_window\n",
    "            \n",
    "            # Check if window contains seizure (ictal)\n",
    "            if seizure_start <= window_center_sec <= seizure_end:\n",
    "                detection_label = 1\n",
    "                timestamp = window_center_sec - seizure_start  # Negative during seizure\n",
    "                break\n",
    "            \n",
    "            # Check if window is in pre-ictal period\n",
    "            elif preictal_start <= window_center_sec < seizure_start:\n",
    "                prediction_label = 1\n",
    "                timestamp = window_center_sec - seizure_start  # Negative, approaches 0\n",
    "                break\n",
    "            \n",
    "            # For inter-ictal, compute time to nearest seizure\n",
    "            else:\n",
    "                dist_to_seizure = min(\n",
    "                    abs(window_center_sec - seizure_start),\n",
    "                    abs(window_center_sec - seizure_end)\n",
    "                )\n",
    "                timestamp = dist_to_seizure if window_center_sec < seizure_start else -dist_to_seizure\n",
    "        \n",
    "        return detection_label, prediction_label, timestamp\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Convert to tensor\n",
    "        eeg_data = torch.FloatTensor(sample['eeg_data']).contiguous()\n",
    "        \n",
    "        # Apply data augmentation in training\n",
    "        if self.mode == 'train':\n",
    "            eeg_data = self._augment_data(eeg_data)\n",
    "        \n",
    "        return {\n",
    "            'eeg': eeg_data,\n",
    "            'detection_label': torch.FloatTensor([sample['detection_label']]),\n",
    "            'prediction_label': torch.FloatTensor([sample['prediction_label']]),\n",
    "            'timestamp': torch.FloatTensor([sample['timestamp']]),\n",
    "            'subject': sample['subject'],\n",
    "            'file': sample['file']\n",
    "        }\n",
    "    \n",
    "    def _augment_data(self, eeg_data):\n",
    "        \"\"\"Apply data augmentation\"\"\"\n",
    "        # Channel dropout\n",
    "        if torch.rand(1) < 0.3:\n",
    "            num_drop = int(config.num_channels * 0.2)\n",
    "            channels_to_drop = torch.randperm(config.num_channels)[:num_drop]\n",
    "            eeg_data[channels_to_drop] = 0\n",
    "        \n",
    "        # Add Gaussian noise\n",
    "        if torch.rand(1) < 0.5:\n",
    "            noise = torch.randn_like(eeg_data) * 0.1\n",
    "            eeg_data = eeg_data + noise\n",
    "        \n",
    "        # Add EMG-like noise (bursts)\n",
    "        if torch.rand(1) < 0.3:\n",
    "            burst_noise = torch.randn_like(eeg_data) * 0.2\n",
    "            mask = torch.rand_like(eeg_data) < 0.1  # 10% of samples get bursts\n",
    "            eeg_data = eeg_data + burst_noise * mask\n",
    "        \n",
    "        # Amplitude scaling\n",
    "        if torch.rand(1) < 0.3:\n",
    "            scale = torch.rand(1) * 0.4 + 0.8  # 0.8 to 1.2\n",
    "            eeg_data = eeg_data * scale\n",
    "            \n",
    "        return eeg_data\n",
    "\n",
    "# Create real dataloaders\n",
    "def create_real_dataloaders(data_path):\n",
    "    \"\"\"Create real dataloaders with CHB-MIT data\"\"\"\n",
    "    # Use first 15 subjects for training, next 5 for validation\n",
    "    all_subjects = [f'chb{i:02d}' for i in range(1, 24)]  # CHB-MIT has subjects chb01 to chb24\n",
    "    \n",
    "    # For demo, use a small subset\n",
    "    train_subjects = all_subjects[:3]\n",
    "    val_subjects = all_subjects[3:4]\n",
    "    \n",
    "    try:\n",
    "        train_dataset = CHBMITDataset(\n",
    "            data_path=data_path,\n",
    "            window_size=config.window_size,\n",
    "            stride=config.stride,\n",
    "            mode='train',\n",
    "            subjects=train_subjects\n",
    "        )\n",
    "        \n",
    "        val_dataset = CHBMITDataset(\n",
    "            data_path=data_path,\n",
    "            window_size=config.window_size,\n",
    "            stride=config.stride,\n",
    "            mode='val',\n",
    "            subjects=val_subjects\n",
    "        )\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "        \n",
    "        return train_loader, val_loader\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating real dataloaders: {e}\")\n",
    "        print(\"Creating mock dataloaders for demonstration...\")\n",
    "        return create_mock_dataloaders()\n",
    "\n",
    "def create_mock_dataloaders():\n",
    "    \"\"\"Create mock dataloaders for demonstration when real data is not available\"\"\"\n",
    "    class MockDataset(Dataset):\n",
    "        def __init__(self, num_samples=1000):\n",
    "            self.num_samples = num_samples\n",
    "            \n",
    "        def __len__(self):\n",
    "            return self.num_samples\n",
    "            \n",
    "        def __getitem__(self, idx):\n",
    "            # Generate realistic EEG-like data\n",
    "            eeg_data = torch.randn(config.num_channels, config.window_size) * 0.1\n",
    "            \n",
    "            # Add some rhythmic components to make it more realistic\n",
    "            t = torch.arange(config.window_size).float() / config.sampling_rate\n",
    "            for i in range(config.num_channels):\n",
    "                freq = torch.rand(1) * 30 + 2  # 2-32 Hz\n",
    "                rhythm = torch.sin(2 * np.pi * freq * t) * 0.05\n",
    "                eeg_data[i] += rhythm\n",
    "            \n",
    "            # Random labels (20% positive for demo)\n",
    "            detection_label = torch.FloatTensor([1.0]) if torch.rand(1) < 0.2 else torch.FloatTensor([0.0])\n",
    "            prediction_label = torch.FloatTensor([1.0]) if torch.rand(1) < 0.15 else torch.FloatTensor([0.0])\n",
    "            timestamp = torch.FloatTensor([torch.randn(1).item() * 100])\n",
    "            \n",
    "            return {\n",
    "                'eeg': eeg_data,\n",
    "                'detection_label': detection_label,\n",
    "                'prediction_label': prediction_label,\n",
    "                'timestamp': timestamp,\n",
    "                'subject': 'mock',\n",
    "                'file': 'mock.edf'\n",
    "            }\n",
    "    \n",
    "    train_dataset = MockDataset(1000)\n",
    "    val_dataset = MockDataset(200)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Initialize dataloaders\n",
    "data_path = \".\"  # Change this to your CHB-MIT data path\n",
    "train_loader, val_loader = create_real_dataloaders(data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sajan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
